{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42f6884",
   "metadata": {},
   "source": [
    "# Ingest and Embed Documents for RAG using LangChain + FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, WebBaseLoader\n",
    "import os\n",
    "\n",
    "!pip install pgvector pypdf psycopg langchain lxml_html_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42997376",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_version = \"2-latest\"\n",
    "CONNECTION_STRING = \"postgresql+psycopg://vectordb:vectordb@postgresql-service.ic-shared-rag-llm.svc.cluster.local:5432/vectordb\"\n",
    "COLLECTION_NAME = \"documents_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load PDF document\n",
    "!pip install pypdf\n",
    "\n",
    "import os\n",
    "print(\"Exists:\", os.path.exists(\"sample_doc.pdf\"))\n",
    "print(\"Found?\" , os.path.exists(\"sample_doc.pdf\"))  # Update path accordingly\n",
    "\n",
    "pdf_path = \"sample_doc.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf73be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split text into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create embeddings for chunks\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46ec95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Store in FAISS vector store\n",
    "\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True # This deletes existing collection and its data, use carefully!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save the FAISS index locally\n",
    "#os.makedirs(\"faiss_index\", exist_ok=True)\n",
    "#db.save_local(\"faiss_index\")\n",
    "#print(\"âœ… Ingestion complete: FAISS index saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc007ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to install a cluster on Azure ?\"\n",
    "docs_with_score = db.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ba6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
